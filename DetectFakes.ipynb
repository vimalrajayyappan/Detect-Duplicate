{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETECT FAKES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will go through the steps what I had done and reason their usage. I had done the whole code in Visual Studio 2017 which helped me with great debugging tools.Following things are meant for demo where I loaded all the .pkl files and MODELS which had been pre built from visual studio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORT FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* remove_punc : This function removes all symbols and punctuations since they are of less importance as a feature\n",
    "* alpha_order : This arranges the column 'product_family' in alphabetical order\n",
    "* avg_word    : Helps in getting average count of words\n",
    "* get_jaccard_sim : Helps in retrieving jaccard similarity between two vectors . like intersection between the same.\n",
    "* ascii_rep       : Representation of 'size' column as unique asciicode representation. I dint use this in code since word2vec handles it nicely\n",
    "* word2vec_feat    : They help in representation of every word in vectors which can then be fed to train the model. Each word here is represented in a vector of size  150\n",
    "\n",
    "* normalize_vect : It normalizes the given vector between a range of -1 to 1.Th formulation is simple.\n",
    "* common_feat    : Using the tf-idf(Term Frequency - Inverse Domain Frequency) a transform is set on which the vector is fitted and a cosine similarity of both vectors are determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- REMOVES THE PUNCTUATIONS AND SYMBOLS --#\n",
    "def remove_punc(inp):\n",
    "    #s = re.sub(r'[^\\w\\s]','',s)\n",
    "    inp=inp.replace(';',' ')\n",
    "    return re.sub(r'[^\\w\\s]','',str(inp))\n",
    "\n",
    "#-- ARRANGES THE PRODUCT FAMILY IN ALPHABETICAL ORDER --#\n",
    "def alpha_order(inp):\n",
    "    return ' '.join(sorted(inp.split(',')))\n",
    "\n",
    "#-- AVERAGE _--#\n",
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "#-- THIS FUNCTION RETRIEVES THE COSINE SIMILARITY BETWEEN TWO VECTORS --#\n",
    "def get_jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "#-- ASCII REPRESENTATION OF SIZE --#\n",
    "def ascii_rep(x):\n",
    "    lst=np.array([ord(ch) for ch in x])\n",
    "    return ((lst/ord('z')).sum())/len(lst)\n",
    "\n",
    "#-- GET WOD TO VEC FEATURE VECTOR --#\n",
    "def word2vec_feat(lst_words,model):\n",
    "    fin_vec=[]\n",
    "    for wrd in lst_words:\n",
    "        try:\n",
    "            fin_vec.append(model[wrd])\n",
    "        except:\n",
    "            fin_vec.append(np.zeros(150).tolist())\n",
    "    fin_vec=np.array(fin_vec)\n",
    "    wd_vec_feat=fin_vec.sum(axis=0)\n",
    "    return wd_vec_feat\n",
    " \n",
    "\n",
    "#-- NORMALIZES THE VECTOR --#\n",
    "def normalize_vect(lst):\n",
    "    return lst/np.sqrt((lst**2).sum())  #v/np.sqrt((v**2).sum())\n",
    "\n",
    "#-- COSINE SIMILARITY BETWEEN TWO SENTENCES --#\n",
    "def common_feat(sentences):\n",
    "    vectorizer=TfidfVectorizer()\n",
    "    tfidf=vectorizer.fit_transform(sentences)\n",
    "    cosine_similarities = linear_kernel(tfidf[0:1], tfidf).flatten()\n",
    "    return cosine_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LETS DIVE IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data_file_pd.pkl is the actual excel data given which is conveted into .pkl \n",
    "* I'm considering only the subcategoy Tops(Kids) containing 311051 rows\n",
    "* I'm not considering images here. Trying to fit a model with words and similarities as features.\n",
    "* Will proceed with some sample outputs\n",
    "* I made use of pandas which helped me in hitting the output in less time without necessities of 'for'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Citrine Casual Short Sleeve Printed Womens Pink White Top This beautiful printed modal top from Citrine is soft against the skin It features mock pockets and a pleat at the back Pair with jeans for a cool and casual look Citrine TOPE9ABBBTJYDSQE TOPE9ABBHJ8HGGGK TOPE9ABBPDAN7VCH S Pink Off White Round Neck Short Sleeve Fabric Modal Pattern Printed Pack of 1 Shweta Mathur'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fields=['productId','title','description','mrp','sellingPrice','specialPrice','categories','productBrand','productFamily','size','color','keySpecsStr','sellerName']\n",
    "#df = pd.read_excel('machine_learn_data_xls.xlsx',converters={'productId':str,'title':str,'description':str,'mrp':str,'sellingPrice':str,'specialPrice':str,'categories':str,'productBrand':str,'productFamily':str,'size':str,'color':str,'keySpecsStr':str,'sellerName':str})\n",
    "df =pd.read_pickle(\"data_file_pd.pkl\")\n",
    "df['productFamily']=df['productFamily'].apply(alpha_order)\n",
    "df['train_set'] = df[['title','description','productBrand','productFamily','size','color','keySpecsStr','sellerName']].apply(lambda x: ' '.join(map(str, x)), axis=1)\n",
    "df['Removed_punc']=df['train_set'].apply(remove_punc)\n",
    "df['Removed_punc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>imageUrlStr</th>\n",
       "      <th>mrp</th>\n",
       "      <th>sellingPrice</th>\n",
       "      <th>specialPrice</th>\n",
       "      <th>productUrl</th>\n",
       "      <th>categories</th>\n",
       "      <th>productBrand</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 45</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>Unnamed: 48</th>\n",
       "      <th>Unnamed: 49</th>\n",
       "      <th>Unnamed: 50</th>\n",
       "      <th>Unnamed: 51</th>\n",
       "      <th>Unnamed: 52</th>\n",
       "      <th>train_set</th>\n",
       "      <th>Removed_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOPE9ABBZU3HZRHN</td>\n",
       "      <td>Citrine Casual Short Sleeve Printed Women's Pi...</td>\n",
       "      <td>This beautiful printed modal top from Citrine ...</td>\n",
       "      <td>http://img.fkcdn.com/image/top/r/h/n/1-1-wwtpw...</td>\n",
       "      <td>1099</td>\n",
       "      <td>329</td>\n",
       "      <td>329</td>\n",
       "      <td>http://dl.flipkart.com/dl/citrine-casual-short...</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tun...</td>\n",
       "      <td>Citrine</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citrine Casual Short Sleeve Printed Women's Pi...</td>\n",
       "      <td>Citrine Casual Short Sleeve Printed Womens Pin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOPE9ABBBTJYDSQE</td>\n",
       "      <td>Citrine Casual Short Sleeve Printed Women's Pi...</td>\n",
       "      <td>This beautiful printed modal top from Citrine ...</td>\n",
       "      <td>http://img.fkcdn.com/image/top/r/h/n/1-1-wwtpw...</td>\n",
       "      <td>1099</td>\n",
       "      <td>329</td>\n",
       "      <td>329</td>\n",
       "      <td>http://dl.flipkart.com/dl/citrine-casual-short...</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tun...</td>\n",
       "      <td>Citrine</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Citrine Casual Short Sleeve Printed Women's Pi...</td>\n",
       "      <td>Citrine Casual Short Sleeve Printed Womens Pin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOPE6XZPUVT9C7RU</td>\n",
       "      <td>Butterfly Wears Casual Short Sleeve Solid Wome...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://img.fkcdn.com/image/top/y/h/c/5245-butt...</td>\n",
       "      <td>799</td>\n",
       "      <td>799</td>\n",
       "      <td>799</td>\n",
       "      <td>http://dl.flipkart.com/dl/butterfly-wears-casu...</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tun...</td>\n",
       "      <td>Butterfly Wears</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Butterfly Wears Casual Short Sleeve Solid Wome...</td>\n",
       "      <td>Butterfly Wears Casual Short Sleeve Solid Wome...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          productId                                              title  \\\n",
       "0  TOPE9ABBZU3HZRHN  Citrine Casual Short Sleeve Printed Women's Pi...   \n",
       "1  TOPE9ABBBTJYDSQE  Citrine Casual Short Sleeve Printed Women's Pi...   \n",
       "2  TOPE6XZPUVT9C7RU  Butterfly Wears Casual Short Sleeve Solid Wome...   \n",
       "\n",
       "                                         description  \\\n",
       "0  This beautiful printed modal top from Citrine ...   \n",
       "1  This beautiful printed modal top from Citrine ...   \n",
       "2                                                NaN   \n",
       "\n",
       "                                         imageUrlStr   mrp sellingPrice  \\\n",
       "0  http://img.fkcdn.com/image/top/r/h/n/1-1-wwtpw...  1099          329   \n",
       "1  http://img.fkcdn.com/image/top/r/h/n/1-1-wwtpw...  1099          329   \n",
       "2  http://img.fkcdn.com/image/top/y/h/c/5245-butt...   799          799   \n",
       "\n",
       "  specialPrice                                         productUrl  \\\n",
       "0          329  http://dl.flipkart.com/dl/citrine-casual-short...   \n",
       "1          329  http://dl.flipkart.com/dl/citrine-casual-short...   \n",
       "2          799  http://dl.flipkart.com/dl/butterfly-wears-casu...   \n",
       "\n",
       "                                          categories     productBrand  \\\n",
       "0  Apparels>Women>Western Wear>Shirts, Tops & Tun...          Citrine   \n",
       "1  Apparels>Women>Western Wear>Shirts, Tops & Tun...          Citrine   \n",
       "2  Apparels>Women>Western Wear>Shirts, Tops & Tun...  Butterfly Wears   \n",
       "\n",
       "                         ...                         Unnamed: 45  Unnamed: 46  \\\n",
       "0                        ...                                 NaN          NaN   \n",
       "1                        ...                                 NaN          NaN   \n",
       "2                        ...                                 NaN          NaN   \n",
       "\n",
       "   Unnamed: 47  Unnamed: 48  Unnamed: 49  Unnamed: 50 Unnamed: 51 Unnamed: 52  \\\n",
       "0          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "1          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "2          NaN          NaN          NaN          NaN         NaN         NaN   \n",
       "\n",
       "                                           train_set  \\\n",
       "0  Citrine Casual Short Sleeve Printed Women's Pi...   \n",
       "1  Citrine Casual Short Sleeve Printed Women's Pi...   \n",
       "2  Butterfly Wears Casual Short Sleeve Solid Wome...   \n",
       "\n",
       "                                        Removed_punc  \n",
       "0  Citrine Casual Short Sleeve Printed Womens Pin...  \n",
       "1  Citrine Casual Short Sleeve Printed Womens Pin...  \n",
       "2  Butterfly Wears Casual Short Sleeve Solid Wome...  \n",
       "\n",
       "[3 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SAMPLE \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LENGTH:', 373)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length\n",
    "df['len_row']= df['Removed_punc'].apply(lambda x: len(str(x)))\n",
    "'LENGTH:',df['len_row'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LENGTH OF CHAR:', 48)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## UNIQUE REPRENTATION OF CHARACTERS\n",
    "df['len_char']=df['Removed_punc'].apply(lambda x : len(''.join(set(str(x).replace(' ','')))))\n",
    "'LENGTH OF CHAR:',df['len_char'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('WORD COUNT', 61)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['len_word']=df['Removed_punc'].apply(lambda x :len(str(x).split()))\n",
    "'WORD COUNT',df['len_word'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('COSINE SMILARITY :', array([1.        , 0.18434916]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#COSINE SMILARITY OF FIRST SENTENCE WITH RESPECT TO SECOND. AVERAGE OF THESE WILL BE USED\n",
    "'COSINE SMILARITY :',common_feat([df['Removed_punc'][0],df['Removed_punc'][45]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('JACCARD SIMILARITY :', 0.1746031746031746)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'JACCARD SIMILARITY :',get_jaccard_sim(df['Removed_punc'][0],df['Removed_punc'][45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASIC FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are some exapmles of basic and common feature extractions. Now lets build positive and negative datasets for training.\n",
    "\n",
    "new_df.pkl file:\n",
    "    This file stores all the extracted basic features in a single vector. They are non-normalized as of now.They contain only the features of individual vectors. The common features are yet to be built and added. \n",
    "    \n",
    " ISSUE : 'gensim' library is not working perfectly in jupyter notebook.Hardly I tried figuring it out. So I have trained the word2vec model and extracted features using VS . I will make use of those files here. The function I used to extract and combine features is:\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def feature_extract(df):\n",
    "   # print('---------------------------------------------------------------------')\n",
    "    print('---------------BASE FEATURES EXTRACTION------------------------------')\n",
    "    df['productFamily']=df['productFamily'].apply(alpha_order)\n",
    "    df['train_set'] = df[['title','description','productBrand','productFamily','size','color','keySpecsStr','sellerName']].apply(lambda x: ' '.join(map(str, x)), axis=1)\n",
    "    df['Removed_punc']=df['train_set'].apply(remove_punc)\n",
    "    df['len_row']= df['Removed_punc'].apply(lambda x: len(str(x)))\n",
    "    print('Length of rows DONE')\n",
    "    df['len_char']=df['Removed_punc'].apply(lambda x : len(''.join(set(str(x).replace(' ','')))))\n",
    "    print('Length of characters DONE')\n",
    "    df['len_word']=df['Removed_punc'].apply(lambda x :len(str(x).split()))\n",
    "    print('Length of words DONE')\n",
    "    df['avg_word']=df['Removed_punc'].apply(lambda x: avg_word(x))\n",
    "    print('Average of words DONE')\n",
    "    df['numerics'] = df['Removed_punc'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "    print('Check Numerics DONE')\n",
    "    df['upper_count'] = df['Removed_punc'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "    print('Upper case counts DONE')\n",
    "    df['lower_case']=df['Removed_punc'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    print('Check Lowercases DONE')\n",
    "    #freqH= pd.Series(' '.join(df['lower_case']).split()).value_counts()[:10]\n",
    "    #df['rmv_most_occuring_words'] = df['lower_case'].apply(lambda x: \" \".join(x for x in x.split() if x not in freqH))  \n",
    "    stop = stopwords.words('english')\n",
    "    df['rmv_stop_word'] = df['lower_case'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    print('Remove stop words DONE')\n",
    "    df['pre_process']=df['rmv_stop_word'].apply(lambda x : gensim.utils.simple_preprocess(x))\n",
    "    print('Preprocessing DONE')\n",
    "    return df\n",
    "\n",
    "#REFERENCE :##TRAINING OF WORD2VEC MODEL - ACTUALLY DONE EXTERNALLY (not in jupyter notebook)\n",
    "def train_word2vec(new_df):\n",
    "    model = gensim.models.Word2Vec(\n",
    "                    new_df['pre_process'],\n",
    "                    size=150,\n",
    "                    window=10,\n",
    "                    min_count=2,\n",
    "                    workers=10)\n",
    "    model.train(new_df['pre_process'], total_examples=len(new_df['pre_process']), epochs=10)\n",
    "    model.save('model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The new_df file is the output of above function\n",
    "df_basic =pd.read_pickle('new_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>imageUrlStr</th>\n",
       "      <th>mrp</th>\n",
       "      <th>sellingPrice</th>\n",
       "      <th>specialPrice</th>\n",
       "      <th>productUrl</th>\n",
       "      <th>categories</th>\n",
       "      <th>productBrand</th>\n",
       "      <th>...</th>\n",
       "      <th>Removed_punc</th>\n",
       "      <th>len_row</th>\n",
       "      <th>len_char</th>\n",
       "      <th>len_word</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper_count</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>rmv_stop_word</th>\n",
       "      <th>pre_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOPE9ABBZU3HZRHN</td>\n",
       "      <td>Citrine Casual Short Sleeve Printed Women's Pi...</td>\n",
       "      <td>This beautiful printed modal top from Citrine ...</td>\n",
       "      <td>http://img.fkcdn.com/image/top/r/h/n/1-1-wwtpw...</td>\n",
       "      <td>1099</td>\n",
       "      <td>329</td>\n",
       "      <td>329</td>\n",
       "      <td>http://dl.flipkart.com/dl/citrine-casual-short...</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tun...</td>\n",
       "      <td>Citrine</td>\n",
       "      <td>...</td>\n",
       "      <td>Citrine Casual Short Sleeve Printed Womens Pin...</td>\n",
       "      <td>373</td>\n",
       "      <td>48</td>\n",
       "      <td>61</td>\n",
       "      <td>5.131148</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>citrine casual short sleeve printed womens pin...</td>\n",
       "      <td>citrine casual short sleeve printed womens pin...</td>\n",
       "      <td>[citrine, casual, short, sleeve, printed, wome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOPE9ABBBTJYDSQE</td>\n",
       "      <td>Citrine Casual Short Sleeve Printed Women's Pi...</td>\n",
       "      <td>This beautiful printed modal top from Citrine ...</td>\n",
       "      <td>http://img.fkcdn.com/image/top/r/h/n/1-1-wwtpw...</td>\n",
       "      <td>1099</td>\n",
       "      <td>329</td>\n",
       "      <td>329</td>\n",
       "      <td>http://dl.flipkart.com/dl/citrine-casual-short...</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tun...</td>\n",
       "      <td>Citrine</td>\n",
       "      <td>...</td>\n",
       "      <td>Citrine Casual Short Sleeve Printed Womens Pin...</td>\n",
       "      <td>373</td>\n",
       "      <td>49</td>\n",
       "      <td>61</td>\n",
       "      <td>5.131148</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>citrine casual short sleeve printed womens pin...</td>\n",
       "      <td>citrine casual short sleeve printed womens pin...</td>\n",
       "      <td>[citrine, casual, short, sleeve, printed, wome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOPE6XZPUVT9C7RU</td>\n",
       "      <td>Butterfly Wears Casual Short Sleeve Solid Wome...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://img.fkcdn.com/image/top/y/h/c/5245-butt...</td>\n",
       "      <td>799</td>\n",
       "      <td>799</td>\n",
       "      <td>799</td>\n",
       "      <td>http://dl.flipkart.com/dl/butterfly-wears-casu...</td>\n",
       "      <td>Apparels&gt;Women&gt;Western Wear&gt;Shirts, Tops &amp; Tun...</td>\n",
       "      <td>Butterfly Wears</td>\n",
       "      <td>...</td>\n",
       "      <td>Butterfly Wears Casual Short Sleeve Solid Wome...</td>\n",
       "      <td>216</td>\n",
       "      <td>45</td>\n",
       "      <td>29</td>\n",
       "      <td>6.482759</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "      <td>[butterfly, wears, casual, short, sleeve, soli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          productId                                              title  \\\n",
       "0  TOPE9ABBZU3HZRHN  Citrine Casual Short Sleeve Printed Women's Pi...   \n",
       "1  TOPE9ABBBTJYDSQE  Citrine Casual Short Sleeve Printed Women's Pi...   \n",
       "2  TOPE6XZPUVT9C7RU  Butterfly Wears Casual Short Sleeve Solid Wome...   \n",
       "\n",
       "                                         description  \\\n",
       "0  This beautiful printed modal top from Citrine ...   \n",
       "1  This beautiful printed modal top from Citrine ...   \n",
       "2                                                NaN   \n",
       "\n",
       "                                         imageUrlStr   mrp sellingPrice  \\\n",
       "0  http://img.fkcdn.com/image/top/r/h/n/1-1-wwtpw...  1099          329   \n",
       "1  http://img.fkcdn.com/image/top/r/h/n/1-1-wwtpw...  1099          329   \n",
       "2  http://img.fkcdn.com/image/top/y/h/c/5245-butt...   799          799   \n",
       "\n",
       "  specialPrice                                         productUrl  \\\n",
       "0          329  http://dl.flipkart.com/dl/citrine-casual-short...   \n",
       "1          329  http://dl.flipkart.com/dl/citrine-casual-short...   \n",
       "2          799  http://dl.flipkart.com/dl/butterfly-wears-casu...   \n",
       "\n",
       "                                          categories     productBrand  \\\n",
       "0  Apparels>Women>Western Wear>Shirts, Tops & Tun...          Citrine   \n",
       "1  Apparels>Women>Western Wear>Shirts, Tops & Tun...          Citrine   \n",
       "2  Apparels>Women>Western Wear>Shirts, Tops & Tun...  Butterfly Wears   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "\n",
       "                                        Removed_punc  len_row  len_char  \\\n",
       "0  Citrine Casual Short Sleeve Printed Womens Pin...      373        48   \n",
       "1  Citrine Casual Short Sleeve Printed Womens Pin...      373        49   \n",
       "2  Butterfly Wears Casual Short Sleeve Solid Wome...      216        45   \n",
       "\n",
       "   len_word  avg_word  numerics upper_count  \\\n",
       "0        61  5.131148         1           4   \n",
       "1        61  5.131148         1           4   \n",
       "2        29  6.482759         1           4   \n",
       "\n",
       "                                          lower_case  \\\n",
       "0  citrine casual short sleeve printed womens pin...   \n",
       "1  citrine casual short sleeve printed womens pin...   \n",
       "2  butterfly wears casual short sleeve solid wome...   \n",
       "\n",
       "                                       rmv_stop_word  \\\n",
       "0  citrine casual short sleeve printed womens pin...   \n",
       "1  citrine casual short sleeve printed womens pin...   \n",
       "2  butterfly wears casual short sleeve solid wome...   \n",
       "\n",
       "                                         pre_process  \n",
       "0  [citrine, casual, short, sleeve, printed, wome...  \n",
       "1  [citrine, casual, short, sleeve, printed, wome...  \n",
       "2  [butterfly, wears, casual, short, sleeve, soli...  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basic.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ASSEMBLING MULTIPLE FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once every thing is done, we have to combine all these features as single vector.The output is stored as fin_df.pkl .\n",
    "This file contains one feature vector combining all features and a sentence whose stop words have been removed.\n",
    "The function that does this is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUTS are basic feature extracted df and word_to_vec model.\n",
    "def assemble_features(new_df,model):\n",
    "   \n",
    "    print('-----------------ASSEMBLING FEATURES STARTED-------------------------')\n",
    "    fin_df = pd.DataFrame(columns=['lst_vect','rmv_word'])\n",
    "    percent=10\n",
    "    for i in range(new_df.shape[0]):\n",
    "        lst_feature=[]\n",
    "        lst_feature.append(new_df['len_row'][i])\n",
    "        lst_feature.append(new_df['len_char'][i])\n",
    "        lst_feature.append(new_df['len_word'][i])\n",
    "        lst_feature.append(new_df['avg_word'][i])\n",
    "        lst_feature.append(new_df['numerics'][i])\n",
    "        lst_feature.append(new_df['upper_count'][i])\n",
    "        lst_feature+=word2vec_feat(new_df['pre_process'][i],model).tolist()\n",
    "        fin_df.loc[i] = [lst_feature,new_df['rmv_stop_word'][i]]\n",
    "        if int(i%(new_df.shape[0]*10/100))==0:\n",
    "            print(percent,'%','completed..')\n",
    "            percent+=10\n",
    "    print('100%','completed..')\n",
    "    print('---------------------------------------------------------------------')\n",
    "    return fin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>lst_vect</th>\n",
       "      <th>rmv_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOPE9ABBZU3HZRHN</td>\n",
       "      <td>[373, 48, 61, 5.131147540983607, 1, 4, -14.944...</td>\n",
       "      <td>citrine casual short sleeve printed womens pin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOPE9ABBBTJYDSQE</td>\n",
       "      <td>[373, 49, 61, 5.131147540983607, 1, 4, -15.067...</td>\n",
       "      <td>citrine casual short sleeve printed womens pin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOPE6XZPUVT9C7RU</td>\n",
       "      <td>[216, 45, 29, 6.482758620689655, 1, 4, -15.808...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOPE6Y7HSDDXPHZN</td>\n",
       "      <td>[238, 49, 32, 6.46875, 1, 5, -8.65605640411377...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOPE6XZPXBP5APH9</td>\n",
       "      <td>[220, 46, 30, 6.366666666666666, 1, 6, -4.3993...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          productId                                           lst_vect  \\\n",
       "0  TOPE9ABBZU3HZRHN  [373, 48, 61, 5.131147540983607, 1, 4, -14.944...   \n",
       "1  TOPE9ABBBTJYDSQE  [373, 49, 61, 5.131147540983607, 1, 4, -15.067...   \n",
       "2  TOPE6XZPUVT9C7RU  [216, 45, 29, 6.482758620689655, 1, 4, -15.808...   \n",
       "3  TOPE6Y7HSDDXPHZN  [238, 49, 32, 6.46875, 1, 5, -8.65605640411377...   \n",
       "4  TOPE6XZPXBP5APH9  [220, 46, 30, 6.366666666666666, 1, 6, -4.3993...   \n",
       "\n",
       "                                            rmv_word  \n",
       "0  citrine casual short sleeve printed womens pin...  \n",
       "1  citrine casual short sleeve printed womens pin...  \n",
       "2  butterfly wears casual short sleeve solid wome...  \n",
       "3  butterfly wears casual short sleeve solid wome...  \n",
       "4  butterfly wears casual short sleeve solid wome...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_pickle('fin_df.pkl')\n",
    "df=pd.concat([df_basic['productId'],df],axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POSITIVE DATA COLLECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we made a single vector of features. Still the common features has to be added and the vector has to be normalized. Using that we can build training data for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I shuffled the data appropriately and stacked two comparable rows side by side. Here we built the positive samples. ie they are non duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "except_top_two_df = df.iloc[2:]\n",
    "top_two=df.head(2)\n",
    "two_stepped_down_df=except_top_two_df.append(top_two,ignore_index=True)\n",
    "df3=pd.DataFrame()\n",
    "df3['lst_vect2']=two_stepped_down_df['lst_vect']\n",
    "df3['rmv_word2']=two_stepped_down_df['rmv_word']\n",
    "no_dup_df=pd.concat([df,df3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>lst_vect</th>\n",
       "      <th>rmv_word</th>\n",
       "      <th>lst_vect2</th>\n",
       "      <th>rmv_word2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOPE9ABBZU3HZRHN</td>\n",
       "      <td>[373, 48, 61, 5.131147540983607, 1, 4, -14.944...</td>\n",
       "      <td>citrine casual short sleeve printed womens pin...</td>\n",
       "      <td>[216, 45, 29, 6.482758620689655, 1, 4, -15.808...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOPE9ABBBTJYDSQE</td>\n",
       "      <td>[373, 49, 61, 5.131147540983607, 1, 4, -15.067...</td>\n",
       "      <td>citrine casual short sleeve printed womens pin...</td>\n",
       "      <td>[238, 49, 32, 6.46875, 1, 5, -8.65605640411377...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOPE6XZPUVT9C7RU</td>\n",
       "      <td>[216, 45, 29, 6.482758620689655, 1, 4, -15.808...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "      <td>[220, 46, 30, 6.366666666666666, 1, 6, -4.3993...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOPE6Y7HSDDXPHZN</td>\n",
       "      <td>[238, 49, 32, 6.46875, 1, 5, -8.65605640411377...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "      <td>[220, 46, 30, 6.366666666666666, 1, 6, -4.6318...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOPE6XZPXBP5APH9</td>\n",
       "      <td>[220, 46, 30, 6.366666666666666, 1, 6, -4.3993...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "      <td>[236, 47, 32, 6.40625, 1, 5, -18.8782730102539...</td>\n",
       "      <td>butterfly wears casual full sleeve solid women...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          productId                                           lst_vect  \\\n",
       "0  TOPE9ABBZU3HZRHN  [373, 48, 61, 5.131147540983607, 1, 4, -14.944...   \n",
       "1  TOPE9ABBBTJYDSQE  [373, 49, 61, 5.131147540983607, 1, 4, -15.067...   \n",
       "2  TOPE6XZPUVT9C7RU  [216, 45, 29, 6.482758620689655, 1, 4, -15.808...   \n",
       "3  TOPE6Y7HSDDXPHZN  [238, 49, 32, 6.46875, 1, 5, -8.65605640411377...   \n",
       "4  TOPE6XZPXBP5APH9  [220, 46, 30, 6.366666666666666, 1, 6, -4.3993...   \n",
       "\n",
       "                                            rmv_word  \\\n",
       "0  citrine casual short sleeve printed womens pin...   \n",
       "1  citrine casual short sleeve printed womens pin...   \n",
       "2  butterfly wears casual short sleeve solid wome...   \n",
       "3  butterfly wears casual short sleeve solid wome...   \n",
       "4  butterfly wears casual short sleeve solid wome...   \n",
       "\n",
       "                                           lst_vect2  \\\n",
       "0  [216, 45, 29, 6.482758620689655, 1, 4, -15.808...   \n",
       "1  [238, 49, 32, 6.46875, 1, 5, -8.65605640411377...   \n",
       "2  [220, 46, 30, 6.366666666666666, 1, 6, -4.3993...   \n",
       "3  [220, 46, 30, 6.366666666666666, 1, 6, -4.6318...   \n",
       "4  [236, 47, 32, 6.40625, 1, 5, -18.8782730102539...   \n",
       "\n",
       "                                           rmv_word2  \n",
       "0  butterfly wears casual short sleeve solid wome...  \n",
       "1  butterfly wears casual short sleeve solid wome...  \n",
       "2  butterfly wears casual short sleeve solid wome...  \n",
       "3  butterfly wears casual short sleeve solid wome...  \n",
       "4  butterfly wears casual full sleeve solid women...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_dup_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NEGATIVE DATA COLLECTION\n",
    "\n",
    "Here Im stacking vectors side by side without shuffling which makes them identical and we end up with a duplicate datasets. You can see their identical nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productId</th>\n",
       "      <th>lst_vect</th>\n",
       "      <th>rmv_word</th>\n",
       "      <th>lst_vect2</th>\n",
       "      <th>rmv_word2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOPE9ABBZU3HZRHN</td>\n",
       "      <td>[373, 48, 61, 5.131147540983607, 1, 4, -14.944...</td>\n",
       "      <td>citrine casual short sleeve printed womens pin...</td>\n",
       "      <td>[373, 48, 61, 5.131147540983607, 1, 4, -14.944...</td>\n",
       "      <td>citrine casual short sleeve printed womens pin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOPE9ABBBTJYDSQE</td>\n",
       "      <td>[373, 49, 61, 5.131147540983607, 1, 4, -15.067...</td>\n",
       "      <td>citrine casual short sleeve printed womens pin...</td>\n",
       "      <td>[373, 49, 61, 5.131147540983607, 1, 4, -15.067...</td>\n",
       "      <td>citrine casual short sleeve printed womens pin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TOPE6XZPUVT9C7RU</td>\n",
       "      <td>[216, 45, 29, 6.482758620689655, 1, 4, -15.808...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "      <td>[216, 45, 29, 6.482758620689655, 1, 4, -15.808...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TOPE6Y7HSDDXPHZN</td>\n",
       "      <td>[238, 49, 32, 6.46875, 1, 5, -8.65605640411377...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "      <td>[238, 49, 32, 6.46875, 1, 5, -8.65605640411377...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOPE6XZPXBP5APH9</td>\n",
       "      <td>[220, 46, 30, 6.366666666666666, 1, 6, -4.3993...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "      <td>[220, 46, 30, 6.366666666666666, 1, 6, -4.3993...</td>\n",
       "      <td>butterfly wears casual short sleeve solid wome...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          productId                                           lst_vect  \\\n",
       "0  TOPE9ABBZU3HZRHN  [373, 48, 61, 5.131147540983607, 1, 4, -14.944...   \n",
       "1  TOPE9ABBBTJYDSQE  [373, 49, 61, 5.131147540983607, 1, 4, -15.067...   \n",
       "2  TOPE6XZPUVT9C7RU  [216, 45, 29, 6.482758620689655, 1, 4, -15.808...   \n",
       "3  TOPE6Y7HSDDXPHZN  [238, 49, 32, 6.46875, 1, 5, -8.65605640411377...   \n",
       "4  TOPE6XZPXBP5APH9  [220, 46, 30, 6.366666666666666, 1, 6, -4.3993...   \n",
       "\n",
       "                                            rmv_word  \\\n",
       "0  citrine casual short sleeve printed womens pin...   \n",
       "1  citrine casual short sleeve printed womens pin...   \n",
       "2  butterfly wears casual short sleeve solid wome...   \n",
       "3  butterfly wears casual short sleeve solid wome...   \n",
       "4  butterfly wears casual short sleeve solid wome...   \n",
       "\n",
       "                                           lst_vect2  \\\n",
       "0  [373, 48, 61, 5.131147540983607, 1, 4, -14.944...   \n",
       "1  [373, 49, 61, 5.131147540983607, 1, 4, -15.067...   \n",
       "2  [216, 45, 29, 6.482758620689655, 1, 4, -15.808...   \n",
       "3  [238, 49, 32, 6.46875, 1, 5, -8.65605640411377...   \n",
       "4  [220, 46, 30, 6.366666666666666, 1, 6, -4.3993...   \n",
       "\n",
       "                                           rmv_word2  \n",
       "0  citrine casual short sleeve printed womens pin...  \n",
       "1  citrine casual short sleeve printed womens pin...  \n",
       "2  butterfly wears casual short sleeve solid wome...  \n",
       "3  butterfly wears casual short sleeve solid wome...  \n",
       "4  butterfly wears casual short sleeve solid wome...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplicate=pd.DataFrame()\n",
    "df_duplicate['lst_vect2']=df['lst_vect']\n",
    "df_duplicate['rmv_word2']=df['rmv_word']\n",
    "df_dup_fin=pd.concat([df,df_duplicate],axis=1)\n",
    "df_dup_fin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMMON FEATURES AND NORMALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using both of these, building of complete feature vector with normalization and addition of common features are done using the function below. This is a time consuming process. Hence I stored the resulting numpy file which I had used for future training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(columns=['features','is_duplicate'])\n",
    "def complete_feature(inp_df):\n",
    "    data_df = pd.DataFrame(columns=['features'])\n",
    "    for indx in range(inp_df.shape[0]):\n",
    "        lst_vect1=normalize_vect(np.array(inp_df['lst_vect'][indx])).tolist()\n",
    "        #print(lst_vect1)\n",
    "        lst_vect2=normalize_vect(np.array(inp_df['lst_vect2'][indx])).tolist()\n",
    "        #print(lst_vect2)\n",
    "        #print(inp_df['rmv_word'][indx])\n",
    "        #print(inp_df['rmv_word2'][indx])\n",
    "        cosine_sim=common_feat([inp_df['rmv_word'][indx],inp_df['rmv_word2'][indx]]).tolist()\n",
    "        #print(cosine_sim)\n",
    "        sim_vect3=sum(cosine_sim)/len(cosine_sim)\n",
    "        #print(sim_vect3)\n",
    "        jac_vect4=get_jaccard_sim(inp_df['rmv_word'][indx],inp_df['rmv_word2'][indx])\n",
    "        #print(jac_vect4)\n",
    "        feat_vect=lst_vect1+lst_vect2\n",
    "        feat_vect.append(sim_vect3)\n",
    "        feat_vect.append(jac_vect4)\n",
    "        #print(feat_vect)\n",
    "        data_df.loc[indx] = [feat_vect]\n",
    "        if indx%(len(inp_df)*10/100)==0:\n",
    "            print(int(indx+1), 'rows completed')\n",
    "    print('------------------------------------------------')\n",
    "    feature_set=np.array([i for i in data_df['features']])\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.load('feat_no_dup.npy')\n",
    "b=np.load('feat_dup.npy')\n",
    "X_train=np.concatenate((a,b),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50825622,  0.06540563,  0.08311965, ..., -0.10151488,\n",
       "         0.60715074,  0.25      ],\n",
       "       [ 0.50812909,  0.06675154,  0.08309886, ..., -0.08546899,\n",
       "         0.62910789,  0.27272727],\n",
       "       [ 0.36518946,  0.07608114,  0.04903007, ..., -0.09684292,\n",
       "         0.80363031,  0.51724138],\n",
       "       ...,\n",
       "       [ 0.49552698,  0.06684528,  0.07992371, ..., -0.08505097,\n",
       "         0.55479937,  0.14285714],\n",
       "       [ 0.56873839,  0.06410241,  0.08865227, ..., -0.11193999,\n",
       "         0.57072952,  0.14814815],\n",
       "       [ 0.52277434,  0.10735545,  0.06301298, ..., -0.08371695,\n",
       "         0.55938964,  0.21212121]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a complete feature vector where the addition of labels is also simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.hstack((np.zeros(len(a)), np.ones(len(b))))\n",
    "#Here 1 represnts they are duplicates and 0 represents they are not duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAINING SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose SVM for classification because considering such type of data and binary classifications SVM works greatly yileding high accuracy.\n",
    "\n",
    "I used simple LinearSVC() as it fits the data well. Since our feature extraction is also great we can make use of SVM to pull out the predictions. I felt using CNNs here is not that necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.52\n",
      "0.984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "svc=LinearSVC()\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_t, X_test, y_t, y_test = train_test_split(X_train, y, test_size=0.3, random_state=rand_state,shuffle=True)\n",
    "t=time.time()\n",
    "svc.fit(X_t, y_t)\n",
    "t2 = time.time()\n",
    "fittingTime = round(t2 - t, 2)\n",
    "accuracy = round(svc.score(X_test, y_test),4)\n",
    "\n",
    "print(fittingTime)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I got around 98.4% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('svc_model.pkl', 'wb') as f:\n",
    "    pickle.dump(svc, f)\n",
    "\n",
    "# # and later you can load it\n",
    "# with open('filename.pkl', 'rb') as f:\n",
    "#     clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Had tested the model with various datasets and its working relatively good. Even I tried visulaizing the decision tree classifier which showed the map and vector indexes decided to classify perfectly. This shows the model is not over fit.\n",
    "\n",
    "* The features are also extracted greatly in which it predicts the class perfectly even the colour and size of the data are altered manually.\n",
    "\n",
    "* This accuracy might become low if we are considering more columns and also if the dataset becomes huge. There we can combat the loss with the use of images which helps the most"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKING AN USER CENTRIC APPLICATION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * The entire python script has been included with this work\n",
    "#### * To trigger the program, just specify the \n",
    "   * 'excel_file_name.xlsx'on which you need to train. \n",
    "    * mode : test or train\n",
    "    \n",
    "#### The program will automatically read in the file,extract features and train model in case if 'train' is specified else\n",
    "#### if test is specified along with the file name\n",
    "#### The program kick starts by picking in the file, start comparing each rows and results the dictionary of corrresponding duplicates\n",
    "\n",
    "## So just feed an excel file and watch it plays!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THANKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LEARNING AND CONCLUSIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This learning is a great opportunity where I came across lot of things to learn right from WordToVec and deep inside SVMs.\n",
    "\n",
    "I thought of adding an extra feature into the vector which is described below:\n",
    "\n",
    "Finding duplicates is mostly a relation so we have to make keen analysis on creating a vector relative to each other. SO assuming that we are having 9 different columns.  Try combining both the columns of each rows making a unique vector form in a shape of 9X9 matrix. Running 1D CNN(Convolutional neural network) over it can give a boost to the accuracy. Since the relative paramters are considered greatly while vector formation and CNN helps maintaining the same.\n",
    "\n",
    "### Looking forward to work with you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
